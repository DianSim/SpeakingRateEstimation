{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9db0e3f-e647-4f54-b5a7-8738eb9a7cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "WORK_DIR = '/Users/dianasimonyan/Desktop/Thesis/Implementation/data_preprocessing'\n",
    "manifest_filepath = f\"{WORK_DIR}/manifest.json\"\n",
    "NEMO_DIR_PATH = '/Users/dianasimonyan/NeMo'\n",
    "manifest_filepath = f\"{WORK_DIR}/manifest.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "658a572e-3960-414a-bbbf-fe5319179f34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo W 2024-03-17 16:18:01 transformer_bpe_models:59] Could not import NeMo NLP collection which is required for speech translation model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/dianasimonyan/NeMo/tools/nemo_forced_aligner/align.py\", line 33, in <module>\n",
      "    from utils.make_ctm_files import make_ctm_files\n",
      "  File \"/Users/dianasimonyan/NeMo/tools/nemo_forced_aligner/utils/make_ctm_files.py\", line 20, in <module>\n",
      "    from nemo.collections.asr.parts.utils.manifest_utils import get_ctm_line\n",
      "ImportError: cannot import name 'get_ctm_line' from 'nemo.collections.asr.parts.utils.manifest_utils' (/Users/dianasimonyan/miniconda3/envs/nemo/lib/python3.10/site-packages/nemo/collections/asr/parts/utils/manifest_utils.py)\n"
     ]
    }
   ],
   "source": [
    "!python $NEMO_DIR_PATH/tools/nemo_forced_aligner/align.py \\\n",
    "  pretrained_name=\"stt_en_fastconformer_hybrid_large_pc\" \\\n",
    "  manifest_filepath=$manifest_filepath \\\n",
    "  output_dir=$WORK_DIR/nfa_output/ \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b433e3f-fa93-46d5-977b-fae1b1aebe48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Copyright (c) 2022, NVIDIA CORPORATION.  All rights reserved.\n",
      "#\n",
      "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
      "# you may not use this file except in compliance with the License.\n",
      "# You may obtain a copy of the License at\n",
      "#\n",
      "#     http://www.apache.org/licenses/LICENSE-2.0\n",
      "#\n",
      "# Unless required by applicable law or agreed to in writing, software\n",
      "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
      "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
      "# See the License for the specific language governing permissions and\n",
      "# limitations under the License.\n",
      "\n",
      "import json\n",
      "import os\n",
      "from collections import Counter\n",
      "from collections import OrderedDict as od\n",
      "from pathlib import Path\n",
      "from typing import Dict, List, Union\n",
      "\n",
      "import librosa\n",
      "import numpy as np\n",
      "\n",
      "from nemo.collections.asr.parts.utils.speaker_utils import (\n",
      "    audio_rttm_map,\n",
      "    get_subsegments,\n",
      "    get_uniqname_from_filepath,\n",
      "    rttm_to_labels,\n",
      "    segments_manifest_to_subsegments_manifest,\n",
      "    write_rttm2manifest,\n",
      ")\n",
      "from nemo.utils.data_utils import DataStoreObject\n",
      "\n",
      "\n",
      "def rreplace(s: str, old: str, new: str) -> str:\n",
      "    \"\"\"\n",
      "    Replace end of string.\n",
      "\n",
      "    Args:\n",
      "        s (str): string to operate on\n",
      "        old (str): ending of string to replace\n",
      "        new (str): replacement for ending of string\n",
      "    Returns:\n",
      "        new.join(li) (string): new string with end replaced\n",
      "    \"\"\"\n",
      "    li = s.rsplit(old, 1)\n",
      "    return new.join(li)\n",
      "\n",
      "\n",
      "def get_uniq_id_with_period(path: str) -> str:\n",
      "    \"\"\"\n",
      "    Get uniq_id from path string with period in it.\n",
      "\n",
      "    Args:\n",
      "        path (str): path to audio file\n",
      "    Returns:\n",
      "        uniq_id (str): unique speaker ID\n",
      "    \"\"\"\n",
      "    split_path = os.path.basename(path).split('.')[:-1]\n",
      "    uniq_id = '.'.join(split_path) if len(split_path) > 1 else split_path[0]\n",
      "    return uniq_id\n",
      "\n",
      "\n",
      "def get_subsegment_dict(subsegments_manifest_file: str, window: float, shift: float, deci: int) -> Dict[str, dict]:\n",
      "    \"\"\"\n",
      "    Get subsegment dictionary from manifest file.\n",
      "\n",
      "    Args:\n",
      "        subsegments_manifest_file (str): Path to subsegment manifest file\n",
      "        window (float): Window length for segmentation\n",
      "        shift (float): Shift length for segmentation\n",
      "        deci (int): Rounding number of decimal places\n",
      "    Returns:\n",
      "        _subsegment_dict (dict): Subsegment dictionary\n",
      "    \"\"\"\n",
      "    _subsegment_dict = {}\n",
      "    with open(subsegments_manifest_file, 'r') as subsegments_manifest:\n",
      "        segments = subsegments_manifest.readlines()\n",
      "        for segment in segments:\n",
      "            segment = segment.strip()\n",
      "            dic = json.loads(segment)\n",
      "            audio, offset, duration, label = dic['audio_filepath'], dic['offset'], dic['duration'], dic['label']\n",
      "            subsegments = get_subsegments(offset=offset, window=window, shift=shift, duration=duration)\n",
      "            if dic['uniq_id'] is not None:\n",
      "                uniq_id = dic['uniq_id']\n",
      "            else:\n",
      "                uniq_id = get_uniq_id_with_period(audio)\n",
      "            if uniq_id not in _subsegment_dict:\n",
      "                _subsegment_dict[uniq_id] = {'ts': [], 'json_dic': []}\n",
      "            for subsegment in subsegments:\n",
      "                start, dur = subsegment\n",
      "            _subsegment_dict[uniq_id]['ts'].append([round(start, deci), round(start + dur, deci)])\n",
      "            _subsegment_dict[uniq_id]['json_dic'].append(dic)\n",
      "    return _subsegment_dict\n",
      "\n",
      "\n",
      "def get_input_manifest_dict(input_manifest_path: str) -> Dict[str, dict]:\n",
      "    \"\"\"\n",
      "    Get dictionary from manifest file.\n",
      "\n",
      "    Args:\n",
      "        input_manifest_path (str): Path to manifest file\n",
      "    Returns:\n",
      "        input_manifest_dict (dict): Dictionary from manifest file\n",
      "    \"\"\"\n",
      "    input_manifest_dict = {}\n",
      "    with open(input_manifest_path, 'r') as input_manifest_fp:\n",
      "        json_lines = input_manifest_fp.readlines()\n",
      "        for json_line in json_lines:\n",
      "            dic = json.loads(json_line)\n",
      "            dic[\"text\"] = \"-\"\n",
      "            uniq_id = get_uniqname_from_filepath(dic[\"audio_filepath\"])\n",
      "            input_manifest_dict[uniq_id] = dic\n",
      "    return input_manifest_dict\n",
      "\n",
      "\n",
      "def write_truncated_subsegments(\n",
      "    input_manifest_dict: Dict[str, dict],\n",
      "    _subsegment_dict: Dict[str, dict],\n",
      "    output_manifest_path: str,\n",
      "    step_count: int,\n",
      "    deci: int,\n",
      "):\n",
      "    \"\"\"\n",
      "    Write subsegments to manifest filepath.\n",
      "\n",
      "    Args:\n",
      "        input_manifest_dict (dict): Input manifest dictionary\n",
      "        _subsegment_dict (dict): Input subsegment dictionary\n",
      "        output_manifest_path (str): Path to output manifest file\n",
      "        step_count (int): Number of the unit segments you want to create per utterance\n",
      "        deci (int): Rounding number of decimal places\n",
      "    \"\"\"\n",
      "    with open(output_manifest_path, 'w') as output_manifest_fp:\n",
      "        for uniq_id, subseg_dict in _subsegment_dict.items():\n",
      "            subseg_array = np.array(subseg_dict['ts'])\n",
      "            subseg_array_idx = np.argsort(subseg_array, axis=0)\n",
      "            chunked_set_count = subseg_array_idx.shape[0] // step_count\n",
      "\n",
      "            for idx in range(chunked_set_count - 1):\n",
      "                chunk_index_stt = subseg_array_idx[:, 0][idx * step_count]\n",
      "                chunk_index_end = subseg_array_idx[:, 1][(idx + 1) * step_count]\n",
      "                offset_sec = subseg_array[chunk_index_stt, 0]\n",
      "                end_sec = subseg_array[chunk_index_end, 1]\n",
      "                dur = round(end_sec - offset_sec, deci)\n",
      "                meta = input_manifest_dict[uniq_id]\n",
      "                meta['offset'] = offset_sec\n",
      "                meta['duration'] = dur\n",
      "                json.dump(meta, output_manifest_fp)\n",
      "                output_manifest_fp.write(\"\\n\")\n",
      "\n",
      "\n",
      "def write_file(name: str, lines: List[dict], idx: int):\n",
      "    \"\"\"\n",
      "    Write json lines to file.\n",
      "\n",
      "    Args:\n",
      "        name (str): Output file path\n",
      "        lines (list): List of json lines\n",
      "        idx (int): Indices to dump to the file\n",
      "    \"\"\"\n",
      "    with open(name, 'w') as fout:\n",
      "        for i in idx:\n",
      "            dic = lines[i]\n",
      "            json.dump(dic, fout)\n",
      "            fout.write('\\n')\n",
      "\n",
      "\n",
      "def read_file(pathlist: str) -> List[str]:\n",
      "    \"\"\"\n",
      "    Read list of lines from target file.\n",
      "\n",
      "    Args:\n",
      "        pathlist (str): Input file path\n",
      "    Returns:\n",
      "        sorted(pathlist) (list): List of lines\n",
      "    \"\"\"\n",
      "    with open(pathlist, 'r') as f:\n",
      "        pathlist = f.readlines()\n",
      "    return sorted(pathlist)\n",
      "\n",
      "\n",
      "def get_dict_from_wavlist(pathlist: List[str]) -> Dict[str, str]:\n",
      "    \"\"\"\n",
      "    Read dictionaries from list of lines\n",
      "\n",
      "    Args:\n",
      "        pathlist (list): List of file paths\n",
      "    Returns:\n",
      "        path_dict (dict): Dictionary containing dictionaries read from files\n",
      "    \"\"\"\n",
      "    path_dict = od()\n",
      "    pathlist = sorted(pathlist)\n",
      "    for line_path in pathlist:\n",
      "        uniq_id = os.path.basename(line_path).split('.')[0]\n",
      "        path_dict[uniq_id] = line_path\n",
      "    return path_dict\n",
      "\n",
      "\n",
      "def get_dict_from_list(data_pathlist: List[str], uniqids: List[str]) -> Dict[str, str]:\n",
      "    \"\"\"\n",
      "    Create dictionaries from list of lines\n",
      "\n",
      "    Args:\n",
      "        data_pathlist (list): List of file paths\n",
      "        uniqids (list): List of file IDs\n",
      "    Returns:\n",
      "        path_dict (dict): Dictionary containing file paths\n",
      "    \"\"\"\n",
      "    path_dict = {}\n",
      "    for line_path in data_pathlist:\n",
      "        uniq_id = os.path.basename(line_path).split('.')[0]\n",
      "        if uniq_id in uniqids:\n",
      "            path_dict[uniq_id] = line_path\n",
      "        else:\n",
      "            raise ValueError(f'uniq id {uniq_id} is not in wav filelist')\n",
      "    return path_dict\n",
      "\n",
      "\n",
      "def get_path_dict(data_path: str, uniqids: List[str], len_wavs: int = None) -> Dict[str, str]:\n",
      "    \"\"\"\n",
      "    Create dictionary from list of lines (using the get_dict_from_list function)\n",
      "\n",
      "    Args:\n",
      "        data_path (str): Path to file containing list of files\n",
      "        uniqids (list): List of file IDs\n",
      "        len_wavs (int): Length of file list\n",
      "    Returns:\n",
      "        data_pathdict (dict): Dictionary containing file paths\n",
      "    \"\"\"\n",
      "    if data_path is not None:\n",
      "        data_pathlist = read_file(data_path)\n",
      "        if len_wavs is not None:\n",
      "            assert len(data_pathlist) == len_wavs\n",
      "            data_pathdict = get_dict_from_list(data_pathlist, uniqids)\n",
      "    elif len_wavs is not None:\n",
      "        data_pathdict = {uniq_id: None for uniq_id in uniqids}\n",
      "    return data_pathdict\n",
      "\n",
      "\n",
      "def create_segment_manifest(\n",
      "    input_manifest_path: str, output_manifest_path: str, window: float, shift: float, step_count: int, deci: int\n",
      "):\n",
      "    \"\"\"\n",
      "    Create segmented manifest file from base manifest file\n",
      "\n",
      "    Args:\n",
      "        input_manifest_path (str): Path to input manifest file\n",
      "        output_manifest_path (str): Path to output manifest file\n",
      "        window (float): Window length for segmentation\n",
      "        shift (float): Shift length for segmentation\n",
      "        step_count (int): Number of the unit segments you want to create per utterance\n",
      "        deci (int): Rounding number of decimal places\n",
      "    \"\"\"\n",
      "    if '.json' not in input_manifest_path:\n",
      "        raise ValueError(\"input_manifest_path file should be .json file format\")\n",
      "    if output_manifest_path and '.json' not in output_manifest_path:\n",
      "        raise ValueError(\"output_manifest_path file should be .json file format\")\n",
      "    elif not output_manifest_path:\n",
      "        output_manifest_path = rreplace(input_manifest_path, '.json', f'_{step_count}seg.json')\n",
      "\n",
      "    input_manifest_dict = get_input_manifest_dict(input_manifest_path)\n",
      "    segment_manifest_path = rreplace(input_manifest_path, '.json', '_seg.json')\n",
      "    subsegment_manifest_path = rreplace(input_manifest_path, '.json', '_subseg.json')\n",
      "    min_subsegment_duration = 0.05\n",
      "    step_count = int(step_count)\n",
      "\n",
      "    AUDIO_RTTM_MAP = audio_rttm_map(input_manifest_path)\n",
      "    segments_manifest_file = write_rttm2manifest(AUDIO_RTTM_MAP, segment_manifest_path, deci)\n",
      "    subsegments_manifest_file = subsegment_manifest_path\n",
      "    segments_manifest_to_subsegments_manifest(\n",
      "        segments_manifest_file, subsegments_manifest_file, window, shift, min_subsegment_duration,\n",
      "    )\n",
      "    subsegments_dict = get_subsegment_dict(subsegments_manifest_file, window, shift, deci)\n",
      "    write_truncated_subsegments(input_manifest_dict, subsegments_dict, output_manifest_path, step_count, deci)\n",
      "    os.remove(segment_manifest_path)\n",
      "    os.remove(subsegment_manifest_path)\n",
      "\n",
      "\n",
      "def create_manifest(\n",
      "    wav_path: str,\n",
      "    manifest_filepath: str,\n",
      "    text_path: str = None,\n",
      "    rttm_path: str = None,\n",
      "    uem_path: str = None,\n",
      "    ctm_path: str = None,\n",
      "    add_duration: bool = False,\n",
      "):\n",
      "    \"\"\"\n",
      "    Create base manifest file\n",
      "\n",
      "    Args:\n",
      "        wav_path (str): Path to list of wav files\n",
      "        manifest_filepath (str): Path to output manifest file\n",
      "        text_path (str): Path to list of text files\n",
      "        rttm_path (str): Path to list of rttm files\n",
      "        uem_path (str): Path to list of uem files\n",
      "        ctm_path (str): Path to list of ctm files\n",
      "        add_duration (bool): Whether to add durations to the manifest file\n",
      "    \"\"\"\n",
      "    if os.path.exists(manifest_filepath):\n",
      "        os.remove(manifest_filepath)\n",
      "    wav_pathlist = read_file(wav_path)\n",
      "    wav_pathdict = get_dict_from_wavlist(wav_pathlist)\n",
      "    len_wavs = len(wav_pathlist)\n",
      "    uniqids = sorted(wav_pathdict.keys())\n",
      "\n",
      "    text_pathdict = get_path_dict(text_path, uniqids, len_wavs)\n",
      "    rttm_pathdict = get_path_dict(rttm_path, uniqids, len_wavs)\n",
      "    uem_pathdict = get_path_dict(uem_path, uniqids, len_wavs)\n",
      "    ctm_pathdict = get_path_dict(ctm_path, uniqids, len_wavs)\n",
      "\n",
      "    lines = []\n",
      "    for uid in uniqids:\n",
      "        wav, text, rttm, uem, ctm = (\n",
      "            wav_pathdict[uid],\n",
      "            text_pathdict[uid],\n",
      "            rttm_pathdict[uid],\n",
      "            uem_pathdict[uid],\n",
      "            ctm_pathdict[uid],\n",
      "        )\n",
      "\n",
      "        audio_line = wav.strip()\n",
      "        if rttm is not None:\n",
      "            rttm = rttm.strip()\n",
      "            labels = rttm_to_labels(rttm)\n",
      "            num_speakers = Counter([l.split()[-1] for l in labels]).keys().__len__()\n",
      "        else:\n",
      "            num_speakers = None\n",
      "\n",
      "        if uem is not None:\n",
      "            uem = uem.strip()\n",
      "\n",
      "        if text is not None:\n",
      "            with open(text.strip()) as f:\n",
      "                text = f.readlines()[0].strip()\n",
      "        else:\n",
      "            text = \"-\"\n",
      "\n",
      "        if ctm is not None:\n",
      "            ctm = ctm.strip()\n",
      "\n",
      "        duration = None\n",
      "        if add_duration:\n",
      "            y, sr = librosa.load(audio_line, sr=None)\n",
      "            duration = librosa.get_duration(y=y, sr=sr)\n",
      "        meta = [\n",
      "            {\n",
      "                \"audio_filepath\": audio_line,\n",
      "                \"offset\": 0,\n",
      "                \"duration\": duration,\n",
      "                \"label\": \"infer\",\n",
      "                \"text\": text,\n",
      "                \"num_speakers\": num_speakers,\n",
      "                \"rttm_filepath\": rttm,\n",
      "                \"uem_filepath\": uem,\n",
      "                \"ctm_filepath\": ctm,\n",
      "            }\n",
      "        ]\n",
      "        lines.extend(meta)\n",
      "\n",
      "    write_file(manifest_filepath, lines, range(len(lines)))\n",
      "\n",
      "\n",
      "def read_manifest(manifest: Union[Path, str]) -> List[dict]:\n",
      "    \"\"\"\n",
      "    Read manifest file\n",
      "\n",
      "    Args:\n",
      "        manifest (str or Path): Path to manifest file\n",
      "    Returns:\n",
      "        data (list): List of JSON items\n",
      "    \"\"\"\n",
      "    manifest = DataStoreObject(str(manifest))\n",
      "\n",
      "    data = []\n",
      "    try:\n",
      "        f = open(manifest.get(), 'r', encoding='utf-8')\n",
      "    except:\n",
      "        raise Exception(f\"Manifest file could not be opened: {manifest}\")\n",
      "    for line in f:\n",
      "        item = json.loads(line)\n",
      "        data.append(item)\n",
      "    f.close()\n",
      "    return data\n",
      "\n",
      "\n",
      "def write_manifest(output_path: Union[Path, str], target_manifest: List[dict], ensure_ascii: bool = True):\n",
      "    \"\"\"\n",
      "    Write to manifest file\n",
      "\n",
      "    Args:\n",
      "        output_path (str or Path): Path to output manifest file\n",
      "        target_manifest (list): List of manifest file entries\n",
      "        ensure_ascii (bool): default is True, meaning the output is guaranteed to have all incoming non-ASCII characters escaped. If ensure_ascii is false, these characters will be output as-is.\n",
      "    \"\"\"\n",
      "    with open(output_path, \"w\", encoding=\"utf-8\") as outfile:\n",
      "        for tgt in target_manifest:\n",
      "            json.dump(tgt, outfile, ensure_ascii=ensure_ascii)\n",
      "            outfile.write('\\n')\n",
      "\n",
      "\n",
      "def write_ctm(output_path: str, target_ctm: Dict[str, dict]):\n",
      "    \"\"\"\n",
      "    Write ctm entries from diarization session to a .ctm file.\n",
      "\n",
      "    Args:\n",
      "        output_path (str): target file path\n",
      "        target_ctm (dict): list of ctm entries\n",
      "    \"\"\"\n",
      "    target_ctm.sort(key=lambda y: y[0])\n",
      "    with open(output_path, \"w\") as outfile:\n",
      "        for pair in target_ctm:\n",
      "            tgt = pair[1]\n",
      "            outfile.write(tgt)\n",
      "\n",
      "\n",
      "def write_text(output_path: str, target_ctm: Dict[str, dict]):\n",
      "    \"\"\"\n",
      "    Write text from diarization session to a .txt file\n",
      "\n",
      "    Args:\n",
      "        output_path (str): target file path\n",
      "        target_ctm (dict): list of ctm entries\n",
      "    \"\"\"\n",
      "    target_ctm.sort(key=lambda y: y[0])\n",
      "    with open(output_path, \"w\") as outfile:\n",
      "        for pair in target_ctm:\n",
      "            tgt = pair[1]\n",
      "            word = tgt.split(' ')[4]\n",
      "            outfile.write(word + ' ')\n",
      "        outfile.write('\\n')\n"
     ]
    }
   ],
   "source": [
    "!cat /Users/dianasimonyan/miniconda3/envs/nemo/lib/python3.10/site-packages/nemo/collections/asr/parts/utils/manifest_utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0d47e8b-013a-46b9-8d75-664e24af650f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.21.0\n"
     ]
    }
   ],
   "source": [
    "import nemo\n",
    "print(nemo.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240ba122-21a8-4585-a3d9-d66d83a360fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
