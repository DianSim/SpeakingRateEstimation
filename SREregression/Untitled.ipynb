{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8e2d71e5-728e-4831-8f08-bc790f765dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import pickle\n",
    "from torchmetrics.regression import PearsonCorrCoef\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "860aac3a-d4d7-4b56-8cb6-db349f194ebe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abs_error_histograms  LSTM\t\t\t\tpreds_csyl.pkl\n",
      "augmentation.py       MatchBoxNet\t\t\tpreds_sp_rate.pkl\n",
      "config.py\t      model_eval_on_given_dataset.py\t__pycache__\n",
      "data_setup.py\t      model_eval.py\t\t\ttrain.py\n",
      "inference.py\t      model_eval_res_common_voices.csv\tUntitled.ipynb\n",
      "labels_csyl.pkl       model.py\t\t\t\tutils.py\n",
      "labels_sp_rate.pkl    models\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "beecc0ab-9dca-46b4-a5ed-b6ea348e8ff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Model                  Corpus  #audios  Language  MSE_csyl  \\\n",
      "0  rMatchBoxNet-3x2x112  LibriSpeech-test-clean     2620   English   16.8507   \n",
      "1  rMatchBoxNet-3x2x112            Common Voice    14813  Armenian   18.4633   \n",
      "2  rMatchBoxNet-3x2x112            Common Voice   163387   Russian   10.7650   \n",
      "3  rMatchBoxNet-3x2x112            Common Voice     6717   English    6.5434   \n",
      "4  rMatchBoxNet-3x2x112            Common Voice   236600   Italian  104.0783   \n",
      "5  rMatchBoxNet-3x2x112            Common Voice   292303   Spanish   12.5045   \n",
      "\n",
      "   PCC_csyl  MSE_sp_rate  PCC_sp_rate  \n",
      "0    0.9918       0.3168       0.8632  \n",
      "1    0.9399       0.5852       0.8106  \n",
      "2    0.9593       0.4041       0.8721  \n",
      "3    0.9233       0.2339       0.8248  \n",
      "4    0.6590      13.2657       0.2781  \n",
      "5    0.9291       0.5307       0.8566  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = 'model_eval_res_common_voices.csv'\n",
    "\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3537918-c3e5-47d3-b0d7-2a8e5eccc9ba",
   "metadata": {},
   "source": [
    "How many syllables will the model say incorrect depends on the length of the audios, the distribution of audio lengthes of the corpus"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
